[{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"required-packages","dir":"Articles","previous_headings":"","what":"Required packages","title":"Partitioning workflow using GBRMPA data","text":"","code":"library(ReefPartitionUniversal) library(terra) library(sf) library(ggplot2) library(exactextractr)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"loading-and-formatting-required-data","dir":"Articles","previous_headings":"","what":"Loading and formatting required data","title":"Partitioning workflow using GBRMPA data","text":"GBRMPA GBR10 raster data downloaded UTM Projected Coordinate Reference Systems. ReefPartitionUniversal requires input data CRS starting. match CRS reproject reef_polygons GDA2020 reprojecting raster data computationally intensive. input data already CRS step required.","code":"# Load reef outline vector data (`canonical-reefs` used here) reef_polygons <- st_read(\"Path to canonical reefs .gpkg\")  # Load bathymetry raster data from GBRMPA GBR10 dataset bathymetry_raster <- rast(   \"Path to Mackay - Capricorn GBR10 bathymetry raster .tif\" )  # Load geomorphic habitat raster data from GBRMPA GBR10 dataset habitat_raster <- rast(   \"Path to Mackay - Capricorn GBR10 geomorphic habitat raster .tif\" )  # Must ensure all input data are in the same CRS reef_polygons <- st_make_valid(st_transform(   reef_polygons,   crs = sf::st_crs(habitat_raster) ))"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"define-arguments-for-workflow","dir":"Articles","previous_headings":"","what":"Define arguments for workflow","title":"Partitioning workflow using GBRMPA data","text":"following code defines arguments use example workflow One Tree Island Reef. includes defining target habitat types habitat_raster, defining desired H3 cell resolution pixel extraction, desired site size clustering.","code":"set.seed(123)  # Define analysis parameters for example: # Pixel values that are used to extract target habitats from # `habitat_raster` habitat_categories <- c(15, 22, 14, 21) # 15: reef crest, 22: reef slope, 14: outer reef flat, 21: sheltered reef slope  # Define hexagon resolution and unit for outputting hexagon area # (same as function defaults) hex_resolution <- 12 unit <- \"m2\"  # Dataframe containing the H3 cell sizes for each resolution # (from https://h3geo.org/docs/core-library/restable/#average-area-in-m2). hex_size <- data.frame(   res = c(7:15),   size = c(5161293, 737327, 105332, 15047, 2149, 307.09, 43.87, 6.267, 0.895) )  # Define the desired site size in terms of spatial area # and the number of H3 cells per site site_size <- 250 * 250 # set size size for our example to 625,000m~2~ n_pixels <- site_size / hex_size[hex_size$res == hex_resolution, ]$size  # Select target reef outline. For this example we use # One Tree Island Reef from the Mackay - Capricorn region OTIR_ID <- \"23055101104\" # One Tree Island Reef target_reef <- reef_polygons[reef_polygons$UNIQUE_ID == OTIR_ID, ]"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"extracting-pixel-data-for-the-target-reef","dir":"Articles","previous_headings":"","what":"Extracting pixel data for the target reef","title":"Partitioning workflow using GBRMPA data","text":"input data arguments set , can extract pixel data One Tree Island Reef using target_reef outline polygon. process involves identifying selected pixels habitat raster object, converting pixels H3 hexagon cells extracting bathymetry data.","code":"pixel_data <- extract_pixel_points(   reef_polygon = target_reef,   habitat_raster = habitat_raster,   add_var_raster = bathymetry_raster,   habitat_categories = habitat_categories )  # We must also attach a reef ID to the dataframe and # remove any pixels with invalid depth data pixel_data$UNIQUE_ID <- OTIR_ID pixel_data <- pixel_data[!is.na(pixel_data$depth), ]  head(pixel_data)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"clustering-habitat-pixels-based-on-distance-and-depth","dir":"Articles","previous_headings":"","what":"Clustering habitat pixels based on distance and depth","title":"Partitioning workflow using GBRMPA data","text":"Data required pixel extracted, can now cluster pixels based geographic distance depth. Using default arguments cluster_reef_pixels() clusters pixels within habitat type using Minimum Spanning Tree adespatial::constr.hclust clustering algorithm. returned dataframe contains row pixel additional column containing clustered site_id.","code":"mst_hclust_pixels <- cluster_reef_pixels(pixel_data, n_pixels = n_pixels)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"creating-site-polygons","dir":"Articles","previous_headings":"","what":"Creating site polygons","title":"Partitioning workflow using GBRMPA data","text":"pixels reef assigned site IDs can collate site polygons use post-processing separate site areas contain large distances smaller site IDs.","code":"# Collate H3 cells that are assigned site IDs into polygons mst_hclust_sites <- clustered_pixels_to_polygons(mst_hclust_pixels)  # Site postprocessing with a minimum number of pixels per site of 50 processed_sites <- site_postprocessing(mst_hclust_sites, min_site_area = 50)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/articles/workflow.html","id":"mapping-outputs-using-ggplot2","dir":"Articles","previous_headings":"","what":"Mapping outputs using ggplot2","title":"Partitioning workflow using GBRMPA data","text":"","code":"# Reorder site ID labels to improve readability sampled_ids <- sample(levels(processed_sites$site_id)) processed_sites$sampled_id <- factor(   processed_sites$site_id,   levels = sampled_ids )  # Plot site polygons coloured by IDs (colours are repeated) id_map <- ggplot() +   geom_sf(data = processed_sites, aes(fill = sampled_id)) +   theme(legend.position = \"none\") # Remove legend due to too many site ID labels  # Re-extract depth data for site polygons for plotting processed_sites$depth <- abs(exact_extract(   bathymetry_raster,   processed_sites,   \"mean\" ))  # Plot sites coloured by mean depth depth_map <- ggplot() +   geom_sf(data = processed_sites, aes(fill = depth)) +   scale_fill_fermenter(     palette = \"greens\",     direction = 1,     breaks = c(2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20)   )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vanessa Haller-Bull. Author, maintainer. Benjamin Grier. Author. Takuya Iwanaga. Author.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Haller-Bull V, Grier B, Iwanaga T (2026). ReefPartitionUniversal: Partition reef habitats sites. R package version 0.0.0.9000, https://open-aims.github.io/ReefPartitionUniversal/.","code":"@Manual{,   title = {ReefPartitionUniversal: Partition reef habitats into sites},   author = {Vanessa Haller-Bull and Benjamin Grier and Takuya Iwanaga},   year = {2026},   note = {R package version 0.0.0.9000},   url = {https://open-aims.github.io/ReefPartitionUniversal/}, }"},{"path":[]},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"package-overview","dir":"","previous_headings":"","what":"Package overview","title":"Partition reef habitats into sites","text":"ReefPartitionAllenAtlas R package provides functions partitioning coral reef spatial areas smaller sites (logistic monitoring purposes) based raster data layers. package provides functions extracting pixel points reef based habitat types, extracting values additional raster layers bathymetry. Pixels can clustered sites within habitat types based geographic attributes well additional variable values pixel depth. package uses flexible framework allowing multiple additional raster layers used, along user defined pixel clustering algorithms. package defines two spatial clustering algorithm options, using adespatial::constr.hclust (Guénard Legendre, 2022) spdep::skater (AssunÇão et al. 2007).","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partition reef habitats into sites","text":"package combines functionality raster vector data processing packages. Dependencies include: sf, terra, sfnetworks, h3, igraph, spdep, adespatial, dplyr magrittr","code":"# Install package using GitHub repo remotes::install_github(\"open-AIMS/ReefPartitionUniversal\")"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"development-installation","dir":"","previous_headings":"","what":"Development installation","title":"Partition reef habitats into sites","text":"convenient way install package local development clone GitHub repository, create branch use following command install package source code.","code":"# Install package from local source folder/repo devtools::install(\"path to package folder\")"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"basic-demonstration","dir":"","previous_headings":"","what":"Basic demonstration","title":"Partition reef habitats into sites","text":"following code demonstrates basic usage ReefPartitionUniversal using adespatial::constr.hclust clustering algorithm Minimum Spanning Tree inputs. ","code":"library(ReefPartitionUniversal)  # Load input data (ensuring all are use the same CRS) target_reef <- sf::st_read(\"target_reef.gpkg\") # Defines the spatial extent of the reef habitat <- terra::rast(\"habitat_raster.tif\") # Defines the habitat pixels to extract from bathymetry <- terra::rast(\"bathymetry_raster.tif\") # Contains additional variable values for extraction and clustering  habitat_categories <- c(1, 10, 20) # Assess only habitat pixels with these values  # Extract pixel values from raster layers pixels <- extract_pixel_points(target_reef, habitat, bathymetry, habitat_categories) pixels <- pixels[!is.na(pixels$depth), ] pixels$UNIQUE_ID <- \"ReefOne\"  # Cluster pixels using adespatial::constr.hclust algorithm # The mst_hclust_pixels <- cluster_reef_pixels(pixels)  # Collate pixels from each site/cluster into polygons mst_hclust_sites <- clustered_pixels_to_polygons(mst_hclust_pixels)  # Optional: Apply post-processing to pixel clusters to ensure that non-contiguous # clusters adhere to a maximum distance between areas. sites_post_processed <- site_postprocessing(mst_hclust_sites, 50)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Partition reef habitats into sites","text":"repository licensed MIT License.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"Partition reef habitats into sites","text":"problems /suggestions encountered package can logged GitHub issues. R package follows tidyverse styleguide.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/index.html","id":"formatting","dir":"","previous_headings":"","what":"Formatting","title":"Partition reef habitats into sites","text":"Code package can auto-formatted follow tidyverse styleguide using formatter Air. installed chosen IDE, using Air commands reformat R files, modifying whitespace, linespace punctuation follow tidyverse styleguide. Additionally, Air set check file formatting new Pull Request made.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2026 ReefPartitionUniversal authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/clustered_pixels_to_polygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert pixels for an entire reef that have been allocated site IDs into site polygons. — clustered_pixels_to_polygons","title":"Convert pixels for an entire reef that have been allocated site IDs into site polygons. — clustered_pixels_to_polygons","text":"dataframe pixels pixel data, function clusters pixels sites (within habitat type), using user defined clustering method considers geographical data additional extracted data (depth).","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/clustered_pixels_to_polygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert pixels for an entire reef that have been allocated site IDs into site polygons. — clustered_pixels_to_polygons","text":"","code":"clustered_pixels_to_polygons(   clustered_pixels,   site_id_col = \"site_id\",   reef_cols_to_keep = c(\"clustering_time\", \"UNIQUE_ID\") )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/clustered_pixels_to_polygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert pixels for an entire reef that have been allocated site IDs into site polygons. — clustered_pixels_to_polygons","text":"clustered_pixels data.frame. Contains row pixel cluster allocations. site_id_col character integer. Column containing site allocations pixels. Default = \"site_id\". reef_cols_to_keep character vector. Columns containing unique values per reef can allocated collated site polygons conserve IDs reef level information. Examples include reef level mean depth, reef distance coastline. Default = c(\"clustering_time\", \"UNIQUE_ID\").","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/clustered_pixels_to_polygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert pixels for an entire reef that have been allocated site IDs into site polygons. — clustered_pixels_to_polygons","text":"sf data.frame containing site polygons created pixels using allocated site_id_col values.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/cluster_reef_pixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster pixels into sites based on geographical attributes and additional extracted pixel values. — cluster_reef_pixels","title":"Cluster pixels into sites based on geographical attributes and additional extracted pixel values. — cluster_reef_pixels","text":"dataframe pixels pixel data, function clusters pixels sites (within habitat type), using user defined clustering method considers geographical data additional extracted data (depth).","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/cluster_reef_pixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster pixels into sites based on geographical attributes and additional extracted pixel values. — cluster_reef_pixels","text":"","code":"cluster_reef_pixels(   pixels,   habitat_col = \"habitat\",   x_col = \"X\",   y_col = \"Y\",   additional_variable_cols = c(\"depth\"),   reef_id_col = \"UNIQUE_ID\",   habitat_clustering_function = constrained_hclust_mst,   ... )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/cluster_reef_pixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster pixels into sites based on geographical attributes and additional extracted pixel values. — cluster_reef_pixels","text":"pixels data.frame. Contains row pixel values variable input habitat_clustering_function. habitat_col character integer. Column containing categorical habitat allocations pixels. Default = \"habitat\". x_col character integer. Column containing continuous geographical X values pixels. Default = \"X\". y_col character integer. Column containing continuous geographical Y values pixels. Default = \"Y\". additional_variable_cols character vector. Vector containing column names columns additional clustering variable values. vector can length > 1. Values standardised output *variable*_standard. Default = c(\"Depth\"). reef_id_col character integer. Column containing single unique reef ID assigned identifier outputting cluster allocations. Default = \"UNIQUE_ID\". habitat_clustering_function function. function takes dataframe pixels single habitat type first argument additional arguments, returns dataframe input pixels additional column containing assigned site_id values. Additional arguments must include px_per_cluster, habitat_col, x_col, y_col additional_variable_cols. Default options available include reef_skater constrained_hclust. px_per_cluster integer. number pixels allocated cluster using habitat_clustering_function. habitat_clustering_function defines k-clusters, must round(nrow(x) / px_per_cluster). Default = 200 pixels.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/cluster_reef_pixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster pixels into sites based on geographical attributes and additional extracted pixel values. — cluster_reef_pixels","text":"data.frame containing pixels site ID allocated site_id column. Output data includes clustering execution time.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster pixels together using the adespatial::constr.hclust algorithm. — constrained_hclust","title":"Cluster pixels together using the adespatial::constr.hclust algorithm. — constrained_hclust","text":"Take dataframe pixels containing additional_variable_cols values edges pixels dataframe cluster using constr.hclust algorithm. clustering performed bottom-based combined distance matrix geographic additional_variable_cols distances pixels connected edges able cluster together. additional information see insert citation/link. pixels contains 30,000 observations interpolation used reduce RAM usage. process randomly samples 30,000 clustering assigns clusters remaining pixels using nearest neighbour interpolation.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster pixels together using the adespatial::constr.hclust algorithm. — constrained_hclust","text":"","code":"constrained_hclust(   pixels,   edges,   x_col = \"X_standard\",   y_col = \"Y_standard\",   additional_variable_cols = c(\"depth_standard\"),   id_col = \"UNIQUE_ID\",   habitat_col = \"habitat\",   distance_method = \"manhattan\",   distance_alpha = 0.5,   beta = -1,   n_pixels = 204,   n_clust = (round(nrow(pixels)/n_pixels)),   method = \"ward.D2\" )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster pixels together using the adespatial::constr.hclust algorithm. — constrained_hclust","text":"pixels data.frame. Contains values X Y coordinates, well additional_variable_cols. edges matrix. Matrix containing edges pixels pixels. x_col character. Name column holding X coordinates. Default = \"X_standard\". y_col character. Name column holding Y coordinates. Default = \"Y_standard\". additional_variable_cols character vector. Names additional columns contribute distance matrix. Default = c(\"depth_standard\"). id_col character. Column holding ID value target reef (attached site_id values output). Default = \"UNIQUE_ID\". habitat_col character. Column holding unique habitat values (attached id_col value site_id values output). Default = \"habitat\". distance_method character. Distance matrix creation method. Default = \"manhattan\" (see dist()). distance_alpha float numeric. Weighting applied additional_variable_cols distance matrix combining geographic distances. (1 - alpha) weighting applied geographic distance matrix. Default = 0.5 (symmetric weighting). beta float numeric. Beta parameter used adespatial::constr.hclust. Parameter value used method == \"flexible\". Default = -1. n_pixels integer numeric. Desired number pixels resulting clusters. Used calculate n_clust (number output clusters). Value used n_clust specification. Default = 204. n_clust integer numeric. Number clusters result output. (Point cut hierarchical clustering tree). Default = (round(nrow(pixels) / n_pixels)) (dividing habitat clusters containing average 200 pixels). method character. Clustering method applied. See adespatial::constr.hclust() details. Default = \"ward.D2\".","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster pixels together using the adespatial::constr.hclust algorithm. — constrained_hclust","text":"data.frame pixels allocated site_ids based cluster outputs. site_id values combination id_col value, habitat_col value cluster allocation.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust_mst.html","id":null,"dir":"Reference","previous_headings":"","what":"Default habitat clustering function using adespatial::constr.hclust. — constrained_hclust_mst","title":"Default habitat clustering function using adespatial::constr.hclust. — constrained_hclust_mst","text":"Take dataframe pixels containing additional_variable_cols values, create minimum spanning tree using prepare_mst_edges() cluster pixels using pixel data edges constrained_hclust(). additional arguments prepare_mst_edges() constrained_hclust() (excluding distance_alpha) can included.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust_mst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default habitat clustering function using adespatial::constr.hclust. — constrained_hclust_mst","text":"","code":"constrained_hclust_mst(pixels, distance_alpha = 0.5, ...)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust_mst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default habitat clustering function using adespatial::constr.hclust. — constrained_hclust_mst","text":"pixels data.frame. Contains values X Y coordinates, well additional_variable_cols. distance_alpha float numeric. Weighting applied additional variable distance values creating distance matrix clustering. argument included ... discoverability. ... additional arguments. Additional arguments can used passed onto prepare_mst_edges() constrained_hclust() functions. arguments must named. distance_alpha argument included additional arguments. information arguments available functions default values arguments used, see prepare_mst_edges() constrained_hclust().","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/constrained_hclust_mst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default habitat clustering function using adespatial::constr.hclust. — constrained_hclust_mst","text":"data.frame pixels allocated site_ids based cluster outputs constrained_hclust() using prepare_mst_edges create minimum spanning tree input. site_id values combination id_col value, habitat_col value cluster allocation.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/extract_pixel_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract pixel data from selected habitats over a target reef. — extract_pixel_points","title":"Extract pixel data from selected habitats over a target reef. — extract_pixel_points","text":"Extract data centroids pixels overlap target reef_polyon. Extraction performed two raster layers, one habitat_raster must contain habitat categories form basis pixel centroids, add_var_raster additional desired data clustering later points workflow.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/extract_pixel_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract pixel data from selected habitats over a target reef. — extract_pixel_points","text":"","code":"extract_pixel_points(   reef_polygon,   habitat_raster,   add_var_raster,   habitat_categories,   hex_resolution = 12,   unit = \"km2\",   additional_variable_name = \"depth\",   output_epsg = 3112,   resample_method = \"bilinear\" )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/extract_pixel_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract pixel data from selected habitats over a target reef. — extract_pixel_points","text":"reef_polygon sf_object. sf object containing target reef polygons data coverage. habitat_raster SpatRaster. Terra raster object containing categorical values habitats covering target reef area. add_var_raster SpatRaster. Terra raster object containing additional variable extract selected habitat pixels covering target reef area. Can continuous categorical, however raster resampled method changed categorical data. habitat_categories character. Vector containing habitat categories select habitat_raster. hex_resolution integer. Selected H3 resolution hexagons pixel representation. Default = 12. unit character. Unit used H3 functions calculate area hexagons. Default = \"km2\". additional_variable_name character. Name assign extracted data add_var_raster. Default = \"depth\". output_epsg integer. EPSG code used outputting pixels extracted data. Default = 3112. resample_method Method used resample add_var_raster extracting pixel data. Default = \"bilinear\", method changed categorical data. See terra::disagg() details.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/extract_pixel_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract pixel data from selected habitats over a target reef. — extract_pixel_points","text":"data.frame containing habitat_raster pixels covering reef_polygon selected habitats habitat_categories, alongside extracted data add_var_raster.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/hex_to_polygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to convert pixels in a single site into an sf poylgon. — hex_to_polygons","title":"Helper function to convert pixels in a single site into an sf poylgon. — hex_to_polygons","text":"Helper function convert pixels single site sf poylgon.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/hex_to_polygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to convert pixels in a single site into an sf poylgon. — hex_to_polygons","text":"","code":"hex_to_polygons(x, h3_id_col = \"id\", site_id_col = \"site_id\")"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/hex_to_polygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to convert pixels in a single site into an sf poylgon. — hex_to_polygons","text":"x data.frame. Contains pixel values target site. h3_id_col character integer. Column containing H3 ID values pixel collated polygon. Default = \"id\". site_id_col charcater vector. Column containing unique site ID target site contained x. Default = \"site_id\".","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/hex_to_polygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to convert pixels in a single site into an sf poylgon. — hex_to_polygons","text":"sf data.frame containing site polygons created pixels using allocated site_id_col values.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/neighborsDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function taken from package expp on 2025-01-20 that converts an spdep::nb neighbors object into a dataframe with columns id and id_neigh. Function copied from expp package to avoid expp dependency as this package is no longer maintained. — neighborsDataFrame","title":"Helper function taken from package expp on 2025-01-20 that converts an spdep::nb neighbors object into a dataframe with columns id and id_neigh. Function copied from expp package to avoid expp dependency as this package is no longer maintained. — neighborsDataFrame","text":"Helper function taken package expp 2025-01-20 converts spdep::nb neighbors object dataframe columns id id_neigh. Function copied expp package avoid expp dependency package longer maintained.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/neighborsDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function taken from package expp on 2025-01-20 that converts an spdep::nb neighbors object into a dataframe with columns id and id_neigh. Function copied from expp package to avoid expp dependency as this package is no longer maintained. — neighborsDataFrame","text":"","code":"neighborsDataFrame(nb)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_knn_edges.html","id":null,"dir":"Reference","previous_headings":"","what":"Create k-nearest-neighbour edges for clustering inputs. — prepare_knn_edges","title":"Create k-nearest-neighbour edges for clustering inputs. — prepare_knn_edges","text":"Take dataframe pixels pixels create k-nearest-neighbour graphs pixels based geographic distances.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_knn_edges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create k-nearest-neighbour edges for clustering inputs. — prepare_knn_edges","text":"","code":"prepare_knn_edges(pixels, k = 7)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_knn_edges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create k-nearest-neighbour edges for clustering inputs. — prepare_knn_edges","text":"pixels sf data.frame. Holds values pixel geometries. k integer. K-nearest-neighbours","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_knn_edges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create k-nearest-neighbour edges for clustering inputs. — prepare_knn_edges","text":"Matrix containing k-n-n edge values pixels.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_mst.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a minimum spanning tree from geographic coordinates of pixels and extracted data. — prepare_mst","title":"Create a minimum spanning tree from geographic coordinates of pixels and extracted data. — prepare_mst","text":"Take dataframe pixels pixels create minimum spanning tree pixel coordinates, using edge costs combination geographic distances distances pixels additional_variable_cols values. additional details minimum spanning tree creation see igraph::mst().","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_mst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a minimum spanning tree from geographic coordinates of pixels and extracted data. — prepare_mst","text":"","code":"prepare_mst(   pixels,   additional_variable_cols = c(\"depth_standard\"),   mst_alpha = 0.5,   hex_resolution = 12 )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_mst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a minimum spanning tree from geographic coordinates of pixels and extracted data. — prepare_mst","text":"pixels sf data.frame. Holds values pixel geometries additional_variable_cols additional_variable_cols character vector. Names columns extract additional (non-geometric) data cost weighting. mst_alpha float numeric. Weighting applied additional_variable_cols distance edge cost weighting combining geographic distances. (1 - alpha) weight applied geographic distance. Default = 0.5 (weight additional_variable_cols geographic distances). hex_resolution integer. H3 hex resolution pixels. Default = 12.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_mst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a minimum spanning tree from geographic coordinates of pixels and extracted data. — prepare_mst","text":"igraph::mst Minimum spanning tree object.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_tri_edges.html","id":null,"dir":"Reference","previous_headings":"","what":"Create triangulated edges from geographic coordinates of pixels. — prepare_tri_edges","title":"Create triangulated edges from geographic coordinates of pixels. — prepare_tri_edges","text":"Take dataframe pixels pixels triangulate vertices. extract edges pixels clustering inputs.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_tri_edges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create triangulated edges from geographic coordinates of pixels. — prepare_tri_edges","text":"","code":"prepare_tri_edges(pixels)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_tri_edges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create triangulated edges from geographic coordinates of pixels. — prepare_tri_edges","text":"pixels sf data.frame. Holds values pixel geometries.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/prepare_tri_edges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create triangulated edges from geographic coordinates of pixels. — prepare_tri_edges","text":"Matrix containing trianguated edge values pixels.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/ReefPartitionUniversal-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ReefPartitionUniversal: Partition reef habitats into sites — ReefPartitionUniversal-package","title":"ReefPartitionUniversal: Partition reef habitats into sites — ReefPartitionUniversal-package","text":"Package partitioning coral reef habitats smaller site areas based raster data layers. package provides functions extracting pixel points reef based habitat types extracting values eadditional raster layers bathymetry. Pixels can clustered sites within habitat types based geographic attributes well additional variable information depth.","code":""},{"path":[]},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/ReefPartitionUniversal-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ReefPartitionUniversal: Partition reef habitats into sites — ReefPartitionUniversal-package","text":"Maintainer: Vanessa Haller-Bull V.Haller@aims.gov.au Authors: Benjamin Grier Takuya Iwanaga","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/reef_skater.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster pixels together using the spdep::skater algorithm. — reef_skater","title":"Cluster pixels together using the spdep::skater algorithm. — reef_skater","text":"Take dataframe pixels containing geometries pixels additional_variable_cols values cluster using skater algorithm. clustering performed top-costs pruning minimum spanning tree edge. pixels connected edges able cluster together. additional information see insert citation/link.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/reef_skater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster pixels together using the spdep::skater algorithm. — reef_skater","text":"","code":"reef_skater(   pixels,   n_clust = round(min(10000, nrow(pixels))/200),   site_size = 250 * 250,   x_col = \"X_standard\",   y_col = \"Y_standard\",   habitat_col = \"habitat\",   id_col = \"UNIQUE_ID\",   additional_variable_cols = c(\"depth_standard\"),   parallelisation = \"Windows\",   hex_resolution = 12 )"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/reef_skater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster pixels together using the spdep::skater algorithm. — reef_skater","text":"pixels data.frame. Contains values X Y coordinates, well additional_variable_cols. n_clust integer numeric. Number clusters result output. (Point cut hierarchical clustering tree). Default = (round(nrow(pixels) / 200)) (dividing habitat clusters containing average 200 pixels). site_size numeric. Desired site size (area m^2). Default = 625,000 (250m x 250m). x_col character. Name column holding X coordinates. Default = \"X_standard\". y_col character. Name column holding Y coordinates. Default = \"Y_standard\". habitat_col character. Column holding unique habitat values (attached id_col value site_id values output). Default = \"habitat\". id_col character. Column holding ID value target reef (attached site_id values output). Default = \"UNIQUE_ID\". additional_variable_cols character vector. Names additional columns contribute distance matrix. Default = c(\"depth_standard\"). parallelisation character. Current option \"Windows\", using option sets parallel::Cluster using detectCores() - 2 cores. parallelises prunecost calculations within spdep::skater(). parallelisation set \"Windows\", parallelisation occur. Default = \"Windows\". hex_resolution integer numeric. H3 hexagon resolution used pixel creation.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/reef_skater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster pixels together using the spdep::skater algorithm. — reef_skater","text":"data.frame pixels allocated site_ids based cluster outputs. site_id values combination id_col value, habitat_col value cluster allocation.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/site_postprocessing.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform post-processing steps on site polygons. — site_postprocessing","title":"Perform post-processing steps on site polygons. — site_postprocessing","text":"Perform post-processing steps site polygons reef. Post- processing applies multipolygons (sites made smaller non-continuous polygons) . process involves identifying largest single polygon removing polygons outside user-defined distance threshold largest polygon. Post-processing also involves removing site polygons small, based user defined minimum site area.","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/site_postprocessing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform post-processing steps on site polygons. — site_postprocessing","text":"","code":"site_postprocessing(reef_site_polygons, min_site_area)"},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/site_postprocessing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform post-processing steps on site polygons. — site_postprocessing","text":"reef_site_polygons data.frame. Contains row unique site, target reef interest. min_site_area numeric. Minimum threshold removing sites small total site area. Must units returned sf::st_area().","code":""},{"path":"https://open-aims.github.io/ReefPartitionUniversal/reference/site_postprocessing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform post-processing steps on site polygons. — site_postprocessing","text":"data.frame containing site polygons target reef post- processing taken place undersized multipolygon sites.","code":""}]
